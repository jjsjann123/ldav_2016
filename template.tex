% $Id: template.tex 11 2007-04-03 22:25:53Z jpeltier $

%\documentclass{vgtc}                          % final (conference style)
\documentclass[review]{vgtc}                 % review
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint]{vgtc}               % preprint
%\documentclass[electronic]{vgtc}             % electronic version

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Figures should be in CMYK or Grey scale format, otherwise, colour 
%% shifting may occur during the printing process.

%% These three lines bring in essential packages: ``mathptmx'' for Type 1 
%% typefaces, ``graphicx'' for inclusion of EPS figures. and ``times''
%% for proper handling of the times font family.

\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{times}
\usepackage{mathtools}
\usepackage[capitalise, noabbrev]{cleveref}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage[detect-all]{siunitx}

\usepackage{libertine} 
\usepackage{siunitx}
\sisetup{per-mode=symbol,per-symbol = p}
%\sisetup{detect-all}
%\DeclareSIUnit{\sample}{S}
%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{112}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in an IEEE VGTC sponsored conference.}

%% Paper title.

\title{NvPipe: A Lightweight H264-based Hardware Accelerated Image Compression Library}

%% This is how authors are specified in the conference style

%% Author and Affiliation (single author).
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}}
%%\affiliation{\scriptsize Allied Widgets Research}

%% Author and Affiliation (multiple authors with single affiliations).
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com} %
%%\and Ed Grimley\thanks{e-mail:ed.grimley@aol.com} %
%%\and Martha Stewart\thanks{e-mail:martha.stewart@marthastewart.com}}
%%\affiliation{\scriptsize Martha Stewart Enterprises \\ Microsoft Research}

%% Author and Affiliation (multiple authors with multiple affiliations)
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}\\ %
%%        \scriptsize Starbucks Research %
%%\and Ed Grimley\thanks{e-mail:ed.grimley@aol.com}\\ %
%%     \scriptsize Grimley Widgets, Inc. %
%%\and Martha Stewart\thanks{e-mail:martha.stewart@marthastewart.com}\\ %
%%     \parbox{1.4in}{\scriptsize \centering Martha Stewart Enterprises \\ Microsoft Research}}
\author{Jie Jiang \thanks{e-mail: jjiang24@uic.edu}\\ %
        \scriptsize University of Illinois at Chicago %
\and Thomas Fogal\thanks{e-mail: tfogal@nvidia.com}\\ %
     \scriptsize NVIDIA %
\and Cliff Woolley\thanks{e-mail: jwoolley@nvidia.com}\\ %
     \scriptsize NVIDIA %
\and Peter Messmer\thanks{e-mail: pmessmer@nvidia.com}\\ %
     \scriptsize NVIDIA} %


%% A teaser figure can be included as follows, but is not recommended since
%% the space is now taken up by a full width abstract.
%\teaser{
%  \includegraphics[width=1.5in]{sample.eps}
%  \caption{Lookit! Lookit!}
%}

%% Abstract section.
\abstract{
Hardware video encoding can lower the perceived latency for remote visualization. NvPipe is a lightweight library that simplifies the use of NVIDIA's video compression hardware. We achieve overall latencies below 15ms with compression ratios of approximately 140:1 and is theoretically capable of supporting 60 FPS streaming over 10mbps network. To verify its applicability in real world scenarios, we integrated NvPipe into ParaView. NvPipe offloads the encoding within ParaView to the GPU and compresses images 30 times better as well. } % end of abstract

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

%\CCScatlist{ 
%  \CCScat{K.6.1}{Management of Computing and Information Systems}%
%{Project and People Management}{Life Cycle};
%  \CCScat{K.7.m}{The Computing Profession}{Miscellaneous}{Ethics}
%}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command
\firstsection{Introduction}

\maketitle

Image compression is commonly used in remote visualization systems to create a smoother user experience over low-bandwidth links. Current systems generally consider each image in isolation even though image differencing approaches can yield considerable data savings.

H.264 is a block-oriented motion-compensation-based video compression standard~\cite{wiegand2003overview}. The standard provides high compression ratios at the cost of significant computational expense. Since the Kepler architecture, NVIDIA provides a hardware-accelerated H.264 encoder~\cite{nvcodec}. It enables real-time encoding with minimal overhead. Support for the encoder has been integrated into popular multimedia frameworks~\cite{ffmpeg}. 

\section{Design}

NvPipe can utilize NVIDIA's hardware encoder or the libx264-based software encoder. We specifically designed NvPipe to abstract away most video compression configuration. A detailed discussion of H.264 parameters is covered in~\cite{wiegand2003overview}. For NvPipe we have configured the encoder to use settings reasonable for visualization. For example, video compression normally has a lag time on the order of tens of frames. For NvPipe we have reduced the lag time to a single frame and guaranteed that the encoder produces a single buffer for every input image, which matches how tools such as ParaView~\cite{henderson2004paraview} and VisIt use image compressors today.

NvPipe handles only image compression and decompression. It leaves streaming to the user for ease of integration.

%NvPipe is built on top of FFmpeg to provide compatibility across systems with and without H.264 hardware. 
%Although NvPipe accepts images with format RGB/RGBA/YUV, it will convert the image into NV12 to before passing it to FFmpeg/NVENC. As is the decompressed image.

\subsection{Performance}

The performance of the compression library is measured by 3 factors: computational efficiency, compression ratio and image quality preservation.

\subsubsection{Compression Ratio}

%put the reference here: http://www.adobe.com/content/dam/Adobe/en/devnet/video/articles/h264_primer/h264_primer.pdf
Compression ratio is determined by the average bitrate parameter of NvPipe. A guideline for bitrate setting is the Kush Gauge~\cite{iszaidyinvestigation}:

\begin{equation}
\label{eq:bitrate}
 bitrate = resolution * \text{framerate} * f_m * 0.07 
\end{equation}

Where \(f_m\) is the "motion factor" that defines the estimated motion of the video on a scale from 1 to 4, with 1 indicating the least motion and 4 the most. NvPipe default bitrate is based on \(f_m=4\) and an estimated 24 frames per second.

The compression ratio \(r_c\) for an 8-bit RGB image is calculated using~\ref{eq:compress_ratio}.

\begin{multline}
\label{eq:compress_ratio}
 %\text{Compression\, ratio:} \\
 r_c = \frac{ resolution * \text{framerate} * 3 * 8}{ bitrate} = \frac{3*8}{0.07f_m} = \frac{342}{f_m} : 1
\end{multline}

\subsubsection{Image Quality}

NvPipe utilizes lossy encoder settings for H.264. Though these settings can introduce artifacts at sharp edges in the image, those errors are not severe as demonstrated by~\ref{fig:quality}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\columnwidth]{quality.eps}
  \caption{1080p image compressed using bitrate calculated with \(f_m=4\). Average structural similarity (SSIM~\cite{wang2004image}) between the images is 98\%. Looking at the block of 60x60 pixels. The right block is the original image and the left block is the recovered image, we can see fine features has been well preserved. }
  \label{fig:quality}
\end{figure}

\section{Results}

%Our experiment setup contains two parts. In part one we benchmark the performance of our library given different resolutions and bitrates. In part two we implement vtkNvpipeCompressor to integrate NvPipe into Paraview. We create a distribute visualization use case and compared the performance of NvPipe with ParaView's native built-in compressor.
We performed a number of experiments to evaluate the utility of H.264 for visualization. All tests were run on an Ubuntu 16.04 machine powered by a NVIDIA GeForce GTX 1080 (Pascal) graphics card.

%Both input and output buffer for compression and decompression are located on host memories. 
Idealy one would source the input images from the already-rendered images on the GPU. However, existing visualization solutions are not architected to easily adhere to this design. Therefore we utilize an interface that accepts data from host memory instead of GPU memory. 

We ran a number of benchmarks to examine the performance and compression ratio of NvPipe. We tested a variety of resolutions to elucidate the relationship between the codec's performance and this factor. We also tried a variety of bitrates but do not highlight the result here because the results are one might expect, lower bitrates produce smaller packets.

%We set up experiment groups using 4 common resolutions. For each one we run 3 cases with low bitrate, medium bitrate and high bitrate settings. The medium setting uses~\cref{eq:bitrate} with \(f_m = 1\) to calculate the bitrate. While low and high uses \(f_m\) of 0.5 and 2 respectively. Each case runs 300 cycles of compressing and decompressing of consecutive images generated with moving color pattern.

Second we integrated NvPipe into ParaView and compared the performance of NvPipe with and without hardware acceleration to built-in compressors utilizing lz4, squirt and Zlib. NvPipe uses high bitrate setting with \(f_m=4\) for best image quality. For configuration of ParaView compressors: Lz4 uses quality level 0. Squirt uses compression level 5. Zlib uses compression level of 9 for slow compression with highest compression ratio, color space reduction level of 5 and alpha channel stripping. Zlib fast uses compression level of 1 for fast compression with lowest compression ratio while other parameters remain the same. The experiments uses 1080p RGBA images generated from rotating volume dataset. The high coherency case applies a fixed small rotation angle of \(1.2\degree\) to the volume data per frame. The low coherency uses larger rotation angle of \(45\degree\) per frame. For each case we run 5 full test each with 300 cycles.

\subsection{NvPipe Benchmark}
% library benchmark

% wouldn't mentioning linear regression make it easier to say this?
Our experiment data shows that NvPipe compression computational complexity is lineary towards the total number of pixels. And the compression time is independent of image data.~\cref{tab:experiment_setup} lists general bandwidth requirements and performance for common resolution. 

%The benchmark experiment shows linear scalability of NvPipe to image size. Given the total number of million pixels of the image to be \(n_p\) and motion factor used for bitrate calculation to be \(f_m\). Linear regression analysis of compression time \(t_c\) and decompression time \(t_d\) generates the following models: \(t_c=2.27n_p+0.16f_m+0.86\) and \(t_d=1.60n_p+0.02f_m+0.89\) with \(R^2_c=99.92\%\) and \(R^2_d=99.97\%\). Performance is linear to total number of pixels in the image with trivial influence from the bitrate multipliccation factor used.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   discuss it if extra room appears later.
%
%Each image compression or decompression call to NvPipe consists of format conversion and encoding or decoding API calls. Computational complexity for both tasks are linear to the totally number of pixels of the input or output image. So we could expect the overall complexity of our compression and decompression call remains linear to the image size.

\begin{table}[h]
  \caption{Computational scalability benchmark measuring average compression and decompression time per frame during 300 frames of RGB images with moving pattern}
  \label{tab:experiment_setup}
  \scriptsize
  \begin{center}
    \begin{tabular}{cccc}
      Resolution & Bitrate(mbps) & Compress(ms) & Decompress(ms)\\
    \hline
      1024x768 & 1.651 & 2.8057 & 2.1170\\
      1280x720 & 1.935 & 3.4793 & 2.4304\\
      1920x1080 & 4.355 & 5.4358 & 4.2876\\
      4096x2160 & 18.579 & 21.2504 & 15.0976
    \end{tabular}
  \end{center}
\end{table}

\subsection{ParaView Integration}

  %ii. ParaView compressors are highly sensitive to data content, notice the symmetric pattern due to the \(360\degree\) rotation, while NvPipe compression ratio stays stable except for the peak due to the key frame every 60 frames. 
  %ParaView built-in compressors use the primary axis on the left while NvPipe hardware and software compressors use the secondary axis on the right. 

Distributed ParaView server uses NvPipe to compress RGBA image buffer and streams compressed image to display client. Our experiment launches both server and client on the same machine to eliminate network latency. 


\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{compressRatio.eps}
  \caption{Compression ratio during high coherency experiemnt. Both the hardware (NP\_hw) and software (NP\_sw) NvPipe compressors have huge compression ratio advantage with above 128:1 versus ParaView's compressors staying between 1.3:1 to 3.4:1.}
  \label{fig:compressRatio}
\end{figure}

~\cref{fig:compressRatio} shows the compression ratio over time of our high coherency experiment. It exhibits the image compression ratio benefit and stability of NvPipe over built-in compressors in ParaView under normal interactive visualization.

% discuss the bandwidth reduction ( compare other paraview compressor )
For more general case, our low coherency experiment shows the computational efficiency in~\cref{fig:time}. Although software-based NvPipe has slower processing performance comparing to lz4 and squirt compressor, the hardware accelerated NvPipe compressor outperforms other tested compressor in both encoding and decoding time.

The average compression ratio \(r_c\) is shown in~\cref{tab:latency}. NvPipe has 42 times better compression ratio comparing to fast Zlib, which is the best compressor tested in Paraview.
The theoretical aggregated latency could be calculated through~\cref{eq:latency}, where communication time \(t_{network}=\frac{\text{compressed image size}}{BW}\). 

\begin{equation}
\label{eq:latency}
T_{latency}=t_{compression}+t_{decompression}+t_{network}
\end{equation}

Assume we have 10mbps available bandwidth, with average compressed image size \(\frac{1920*1080*8*3}{r_c}\) we could calculate the communication time for each compressor. Combining data from~\cref{fig:time} we get the overall latency in~\cref{tab:latency}.

% discuss encoding/decoding time --> framerate / latency 
\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{Performance.eps}
  \caption{ Average compress and decompress time of large rotation experiment. For NvPipe we stack the time of format conversion and compress/decompress time. NvPipe software approach takes much longer time for image compression. While NvPipe hardware compressor outperforms other compressors.}
  \label{fig:time}
\end{figure}

\begin{table}[htb]
  \caption{Average compression ratio and theoretical latency using 10mbps network of low coherency experiment. The lower ratio means better compressed. H.264 has much better compression ratio as well as higher computational complexity as can be seen from the encoding time of NvPipe software. For the overall latency NvPipe hardware approach has 4 times speed up comparing to the second fasted compressor LZ4}
  \label{tab:latency}
  \scriptsize
  \begin{center}
    \begin{tabular}{ccccccc}
      & LZ4 & Squirt & Zlib & Zlib\_fast & NP\_hw & NP\_sw \\
    \hline
      \(r_c\) & 1.29:1 & 1.43:1 & 3.43:1 & 2.78:1 & 144:1 & 152:1 \\
      \(t_{network}\)(ms) & 483.2 & 434.1 & 181.1 & 223.7 & 4.3 & 4.1 \\
      \(T_{latency}\)(ms) & 504.2 & 461.8 & 438.8 & 473.8 & 16.6 & 51.9 \\
      FPS & 2.0 & 2.2 & 2.3 & 2.1 & 60.1 & 19.3 
    \end{tabular}
  \end{center}
\end{table}


\section{Conclusion}

%NvPipe exhibits competitive efficiency among other compressors in \cref{fig:time}. The average overall compression and decompression time is only 12.78ms. And the average encoding and decoding time for FFmpeg API call are 3.938ms and 3.029ms. They yield framerates of 254fps and 330fps respectively. Because of the overhead introduced through FFmpeg wrapper they are expected to be lower than 398fps/658fps released by \cite{ref_1}.% cite nv codec menu.

NvPipe demonstrates great potential with its image quality preservation, compression ratio and efficiency. It could reduce overall latency and improve framerate for distributed visualization system with limited bandwidth. 

% This is Peter's add-on for conclusion.
In future research it will be intereting to investigate the performance of lossless H.264 configuration and HEVC standard~\cite{sullivan2012overview} provided with NVIDIA NvENC API. Other areas of investigations are towards more asynchronocity in this compression process: NvENC is entirely asynchronous to the rest of the GPU, with the potential to completely hide the encoding latency. On the other hand, software only approaches will not be able to fully hide that cost.

%\acknowledgements{
%NVIDIA standard acknowledgement for funding?
%}

%\pagebreak

\bibliographystyle{abbrv}
%%use following if all content of bibtex file should be shown
%\nocite{*}
\bibliography{template}
\end{document}
